{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b7c918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de filas listas para modelar: 8424\n",
      "\n",
      "--- COMENZANDO ENTRENAMIENTO DE LA RED NEURONAL ---\n",
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/keras/src/layers/core/embedding.py:97: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0101 - mae: 0.0714 - val_loss: 0.0074 - val_mae: 0.0641\n",
      "Epoch 2/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0101 - mae: 0.0714 - val_loss: 0.0074 - val_mae: 0.0641\n",
      "Epoch 2/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mae: 0.0651 - val_loss: 0.0072 - val_mae: 0.0622\n",
      "Epoch 3/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0085 - mae: 0.0651 - val_loss: 0.0072 - val_mae: 0.0622\n",
      "Epoch 3/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mae: 0.0637 - val_loss: 0.0077 - val_mae: 0.0654\n",
      "Epoch 4/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0082 - mae: 0.0637 - val_loss: 0.0077 - val_mae: 0.0654\n",
      "Epoch 4/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0628 - val_loss: 0.0068 - val_mae: 0.0604\n",
      "Epoch 5/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0080 - mae: 0.0628 - val_loss: 0.0068 - val_mae: 0.0604\n",
      "Epoch 5/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0624 - val_loss: 0.0074 - val_mae: 0.0631\n",
      "Epoch 6/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0079 - mae: 0.0624 - val_loss: 0.0074 - val_mae: 0.0631\n",
      "Epoch 6/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0622 - val_loss: 0.0073 - val_mae: 0.0610\n",
      "Epoch 7/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0078 - mae: 0.0622 - val_loss: 0.0073 - val_mae: 0.0610\n",
      "Epoch 7/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0614 - val_loss: 0.0077 - val_mae: 0.0641\n",
      "Epoch 8/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0077 - mae: 0.0614 - val_loss: 0.0077 - val_mae: 0.0641\n",
      "Epoch 8/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0613 - val_loss: 0.0073 - val_mae: 0.0605\n",
      "Epoch 9/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0076 - mae: 0.0613 - val_loss: 0.0073 - val_mae: 0.0605\n",
      "Epoch 9/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mae: 0.0608 - val_loss: 0.0073 - val_mae: 0.0621\n",
      "Epoch 10/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0075 - mae: 0.0608 - val_loss: 0.0073 - val_mae: 0.0621\n",
      "Epoch 10/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0608 - val_loss: 0.0076 - val_mae: 0.0641\n",
      "Epoch 11/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0608 - val_loss: 0.0076 - val_mae: 0.0641\n",
      "Epoch 11/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0607 - val_loss: 0.0078 - val_mae: 0.0637\n",
      "Epoch 12/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0074 - mae: 0.0607 - val_loss: 0.0078 - val_mae: 0.0637\n",
      "Epoch 12/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mae: 0.0599 - val_loss: 0.0076 - val_mae: 0.0627\n",
      "Epoch 13/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0073 - mae: 0.0599 - val_loss: 0.0076 - val_mae: 0.0627\n",
      "Epoch 13/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0599 - val_loss: 0.0075 - val_mae: 0.0620\n",
      "Epoch 14/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0599 - val_loss: 0.0075 - val_mae: 0.0620\n",
      "Epoch 14/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0595 - val_loss: 0.0079 - val_mae: 0.0641\n",
      "Epoch 15/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0072 - mae: 0.0595 - val_loss: 0.0079 - val_mae: 0.0641\n",
      "Epoch 15/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0592 - val_loss: 0.0075 - val_mae: 0.0607\n",
      "Epoch 16/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0592 - val_loss: 0.0075 - val_mae: 0.0607\n",
      "Epoch 16/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0591 - val_loss: 0.0088 - val_mae: 0.0691\n",
      "Epoch 17/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0591 - val_loss: 0.0088 - val_mae: 0.0691\n",
      "Epoch 17/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0593 - val_loss: 0.0081 - val_mae: 0.0650\n",
      "Epoch 18/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0071 - mae: 0.0593 - val_loss: 0.0081 - val_mae: 0.0650\n",
      "Epoch 18/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0587 - val_loss: 0.0078 - val_mae: 0.0615\n",
      "Epoch 19/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0587 - val_loss: 0.0078 - val_mae: 0.0615\n",
      "Epoch 19/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0587 - val_loss: 0.0079 - val_mae: 0.0628\n",
      "Epoch 20/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0069 - mae: 0.0587 - val_loss: 0.0079 - val_mae: 0.0628\n",
      "Epoch 20/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0585 - val_loss: 0.0080 - val_mae: 0.0631\n",
      "Epoch 21/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0585 - val_loss: 0.0080 - val_mae: 0.0631\n",
      "Epoch 21/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0584 - val_loss: 0.0077 - val_mae: 0.0618\n",
      "Epoch 22/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0068 - mae: 0.0584 - val_loss: 0.0077 - val_mae: 0.0618\n",
      "Epoch 22/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0578 - val_loss: 0.0086 - val_mae: 0.0652\n",
      "Epoch 23/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0578 - val_loss: 0.0086 - val_mae: 0.0652\n",
      "Epoch 23/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0577 - val_loss: 0.0086 - val_mae: 0.0652\n",
      "Epoch 24/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0067 - mae: 0.0577 - val_loss: 0.0086 - val_mae: 0.0652\n",
      "Epoch 24/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mae: 0.0574 - val_loss: 0.0086 - val_mae: 0.0648\n",
      "Epoch 25/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mae: 0.0574 - val_loss: 0.0086 - val_mae: 0.0648\n",
      "Epoch 25/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mae: 0.0574 - val_loss: 0.0085 - val_mae: 0.0643\n",
      "Epoch 26/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0066 - mae: 0.0574 - val_loss: 0.0085 - val_mae: 0.0643\n",
      "Epoch 26/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0570 - val_loss: 0.0086 - val_mae: 0.0649\n",
      "Epoch 27/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0570 - val_loss: 0.0086 - val_mae: 0.0649\n",
      "Epoch 27/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0570 - val_loss: 0.0082 - val_mae: 0.0624\n",
      "Epoch 28/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0065 - mae: 0.0570 - val_loss: 0.0082 - val_mae: 0.0624\n",
      "Epoch 28/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0567 - val_loss: 0.0082 - val_mae: 0.0634\n",
      "Epoch 29/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0567 - val_loss: 0.0082 - val_mae: 0.0634\n",
      "Epoch 29/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0568 - val_loss: 0.0084 - val_mae: 0.0626\n",
      "Epoch 30/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0568 - val_loss: 0.0084 - val_mae: 0.0626\n",
      "Epoch 30/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0565 - val_loss: 0.0088 - val_mae: 0.0651\n",
      "Epoch 31/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0064 - mae: 0.0565 - val_loss: 0.0088 - val_mae: 0.0651\n",
      "Epoch 31/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0564 - val_loss: 0.0086 - val_mae: 0.0644\n",
      "Epoch 32/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0063 - mae: 0.0564 - val_loss: 0.0086 - val_mae: 0.0644\n",
      "Epoch 32/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0557 - val_loss: 0.0088 - val_mae: 0.0653\n",
      "Epoch 33/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0557 - val_loss: 0.0088 - val_mae: 0.0653\n",
      "Epoch 33/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0560 - val_loss: 0.0088 - val_mae: 0.0658\n",
      "Epoch 34/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0560 - val_loss: 0.0088 - val_mae: 0.0658\n",
      "Epoch 34/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0557 - val_loss: 0.0085 - val_mae: 0.0657\n",
      "Epoch 35/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0062 - mae: 0.0557 - val_loss: 0.0085 - val_mae: 0.0657\n",
      "Epoch 35/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mae: 0.0555 - val_loss: 0.0091 - val_mae: 0.0683\n",
      "Epoch 36/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0061 - mae: 0.0555 - val_loss: 0.0091 - val_mae: 0.0683\n",
      "Epoch 36/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0552 - val_loss: 0.0095 - val_mae: 0.0685\n",
      "Epoch 37/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0552 - val_loss: 0.0095 - val_mae: 0.0685\n",
      "Epoch 37/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0550 - val_loss: 0.0090 - val_mae: 0.0660\n",
      "Epoch 38/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0550 - val_loss: 0.0090 - val_mae: 0.0660\n",
      "Epoch 38/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0552 - val_loss: 0.0085 - val_mae: 0.0642\n",
      "Epoch 39/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0060 - mae: 0.0552 - val_loss: 0.0085 - val_mae: 0.0642\n",
      "Epoch 39/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0547 - val_loss: 0.0091 - val_mae: 0.0661\n",
      "Epoch 40/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.0059 - mae: 0.0547 - val_loss: 0.0091 - val_mae: 0.0661\n",
      "Epoch 40/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0058 - mae: 0.0543 - val_loss: 0.0089 - val_mae: 0.0658\n",
      "Epoch 41/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0058 - mae: 0.0543 - val_loss: 0.0089 - val_mae: 0.0658\n",
      "Epoch 41/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0543 - val_loss: 0.0099 - val_mae: 0.0713\n",
      "Epoch 42/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0543 - val_loss: 0.0099 - val_mae: 0.0713\n",
      "Epoch 42/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0541 - val_loss: 0.0086 - val_mae: 0.0651\n",
      "Epoch 43/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0541 - val_loss: 0.0086 - val_mae: 0.0651\n",
      "Epoch 43/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0540 - val_loss: 0.0085 - val_mae: 0.0642\n",
      "Epoch 44/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0058 - mae: 0.0540 - val_loss: 0.0085 - val_mae: 0.0642\n",
      "Epoch 44/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0538 - val_loss: 0.0089 - val_mae: 0.0657\n",
      "Epoch 45/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0538 - val_loss: 0.0089 - val_mae: 0.0657\n",
      "Epoch 45/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0537 - val_loss: 0.0094 - val_mae: 0.0682\n",
      "Epoch 46/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0537 - val_loss: 0.0094 - val_mae: 0.0682\n",
      "Epoch 46/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0536 - val_loss: 0.0088 - val_mae: 0.0652\n",
      "Epoch 47/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0536 - val_loss: 0.0088 - val_mae: 0.0652\n",
      "Epoch 47/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0531 - val_loss: 0.0095 - val_mae: 0.0686\n",
      "Epoch 48/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0057 - mae: 0.0531 - val_loss: 0.0095 - val_mae: 0.0686\n",
      "Epoch 48/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mae: 0.0532 - val_loss: 0.0087 - val_mae: 0.0648\n",
      "Epoch 49/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0056 - mae: 0.0532 - val_loss: 0.0087 - val_mae: 0.0648\n",
      "Epoch 49/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mae: 0.0526 - val_loss: 0.0088 - val_mae: 0.0649\n",
      "Epoch 50/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mae: 0.0526 - val_loss: 0.0088 - val_mae: 0.0649\n",
      "Epoch 50/50\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mae: 0.0529 - val_loss: 0.0088 - val_mae: 0.0651\n",
      "\u001b[1m205/205\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0055 - mae: 0.0529 - val_loss: 0.0088 - val_mae: 0.0651\n",
      "✅ Entrenamiento del Modelo de Red Neuronal Finalizado.\n",
      "✅ Entrenamiento del Modelo de Red Neuronal Finalizado.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 4.2. Entrenamiento\n",
    "print(\"\\n--- COMENZANDO ENTRENAMIENTO DE LA RED NEURONAL ---\")\n",
    "history = model.fit(\n",
    "    x=[X_cuadrante_train, X_num_train],\n",
    "    y=Y_train,\n",
    "    validation_data=([X_cuadrante_val, X_num_val], Y_val),\n",
    "    epochs=50, \n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "print(\"✅ Entrenamiento del Modelo de Red Neuronal Finalizado.\")\n",
    "\n",
    "\n",
    "# --- 5. PREPARACIÓN Y PREDICCIÓN FINAL (Ejemplo para Enero 2024) ---\n",
    "\n",
    "# Usamos el set de prueba para demostrar la predicción\n",
    "X_cuadrante_test = df_test['CUADRANTE_ID'].values.astype(np.int32)\n",
    "X_num_test = df_test[features].values.astype(np.float32)\n",
    "\n",
    "# 5.1. Predicción en escala normalizada\n",
    "y_pred_scaled = model.predict([X_cuadrante_test, X_num_test])\n",
    "\n",
    "# 5.2. Desnormalizar la predicción\n",
    "# Se crea un array 2D para inverse_transform\n",
    "y_pred_denormalized = scaler_robos_total.inverse_transform(y_pred_scaled)\n",
    "\n",
    "# 5.3. Formatear las 78 Salidas\n",
    "df_results = pd.DataFrame({\n",
    "    'CUADRANTE_ID': df_test['CUADRANTE_ID'].values,\n",
    "    'FECHA': df_test['FECHA'].values,\n",
    "    'PREDICCION_ROBOS_REAL': y_pred_denormalized.flatten()\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a58f4f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TOP 10 CUADRANTES CON MAYOR INCIDENCIA (Predicción para Enero 2024) ---\n",
      "     CUADRANTE_ID  PREDICCION_ROBOS_REAL\n",
      "0               1                      0\n",
      "12              2                      0\n",
      "24              3                      0\n",
      "36              4                      0\n",
      "48              5                      0\n",
      "60              6                      0\n",
      "72              7                      0\n",
      "84              8                      0\n",
      "96              9                      0\n",
      "108            10                      0\n"
     ]
    }
   ],
   "source": [
    "# Filtrar un mes específico y ordenar (ej: Enero 2024)\n",
    "MES_A_EVALUAR = 1\n",
    "prediccion_enero = df_results[df_results['FECHA'].dt.month == MES_A_EVALUAR].copy()\n",
    "prediccion_enero['PREDICCION_ROBOS_REAL'] = prediccion_enero['PREDICCION_ROBOS_REAL'].round(0).astype(int)\n",
    "prediccion_enero = prediccion_enero.sort_values(by='PREDICCION_ROBOS_REAL', ascending=False)\n",
    "\n",
    "\n",
    "print(f\"\\n--- TOP 10 CUADRANTES CON MAYOR INCIDENCIA (Predicción para Enero 2024) ---\")\n",
    "print(prediccion_enero[['CUADRANTE_ID', 'PREDICCION_ROBOS_REAL']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6e4c29a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0987927f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629638ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f464f72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b8e497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Carga y Transformación de Formato Ancho a Largo ---\n",
    "\n",
    "file_name = \"cuadrantes_negocios.csv\"\n",
    "df_wide = pd.read_csv(file_name)\n",
    "\n",
    "\n",
    "# Renombrar 'CUADRANTE' a 'CUADRANTE_ID' y 'POBLACION'\n",
    "df_wide.rename(columns={'CUADRANTE': 'CUADRANTE_ID', 'POBLACION': 'POBLACION_BASE'}, inplace=True)\n",
    "\n",
    "# Identificar las columnas de robos (todas las columnas excepto 'CUADRANTE_ID' y 'POBLACION_BASE')\n",
    "id_vars = ['CUADRANTE_ID', 'POBLACION_BASE']\n",
    "value_vars = [col for col in df_wide.columns if col not in id_vars]\n",
    "\n",
    "# Transformación de Formato Ancho a Largo (Melting)\n",
    "# Esto crea una fila por cada combinación de Cuadrante y Mes/Año\n",
    "df_long = df_wide.melt(\n",
    "    id_vars=id_vars,\n",
    "    value_vars=value_vars,\n",
    "    var_name='MES_AÑO_STR', # Columna temporal que contiene el mes y el año\n",
    "    value_name='ROBOS_TOTAL' # La variable objetivo\n",
    ").copy()\n",
    "\n",
    "# 1.1. Parsear la columna MES_AÑO_STR para crear la columna de FECHA\n",
    "# Ejemplo: 'ROBOS A NEGOCIOS MES 1 2015' -> Enero 2015\n",
    "def parse_date(date_str):\n",
    "    # Separar la cadena por espacios\n",
    "    parts = date_str.split(' ')\n",
    "    mes = parts[4] # Ej: '1'\n",
    "    año = parts[5] # Ej: '2015'\n",
    "    return f'{año}-{mes}-01'\n",
    "\n",
    "df_long['FECHA'] = df_long['MES_AÑO_STR'].apply(parse_date)\n",
    "df_long['FECHA'] = pd.to_datetime(df_long['FECHA'])\n",
    "df_long.sort_values(by=['CUADRANTE_ID', 'FECHA'], inplace=True)\n",
    "df_long.drop(columns=['MES_AÑO_STR'], inplace=True)\n",
    "\n",
    "\n",
    "# --- 2. Generación de Características Temporales ---\n",
    "\n",
    "df_long['AÑO'] = df_long['FECHA'].dt.year\n",
    "df_long['MES'] = df_long['FECHA'].dt.month\n",
    "# df_long['DIA_DEL_MES'] = df_long['FECHA'].dt.day # Si fuera relevante, pero para mensual, el mes ya lo captura\n",
    "\n",
    "# --- 3. Generación de Características Históricas (Retardos) ---\n",
    "\n",
    "# Agrupar por CUADRANTE_ID para asegurar que el retardo sea solo dentro de esa serie de tiempo.\n",
    "df_long['ROBOS_t-1'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].shift(1)\n",
    "df_long['ROBOS_t-12'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].shift(12)\n",
    "\n",
    "# Generación de la Media Móvil de 3 meses (excluyendo el mes actual)\n",
    "# Usamos un Rolling Window de 3 periodos y lo shift(1) para aplicarlo al mes siguiente.\n",
    "df_long['MEDIA_MOVIL_3M'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True).shift(1)\n",
    "\n",
    "\n",
    "# --- 4. Limpieza Final para el Modelo ---\n",
    "\n",
    "# Eliminar las filas que tienen valores NaN en los retardos (los primeros 12 meses de cada cuadrante)\n",
    "# Estos no tienen suficiente historial para las variables t-12.\n",
    "df_model_input = df_long.dropna(subset=['ROBOS_t-12']).copy()\n",
    "\n",
    "# Seleccionar solo las columnas que servirán como entradas (X) y la salida (Y)\n",
    "# NOTA: La POBLACION_BASE es estática. Otras variables como la violencia se añadirían aquí.\n",
    "columnas_finales = [\n",
    "    'CUADRANTE_ID',\n",
    "    'FECHA',\n",
    "    'AÑO',\n",
    "    'MES',\n",
    "    'POBLACION_BASE',\n",
    "    'ROBOS_t-1',\n",
    "    'ROBOS_t-12',\n",
    "    'MEDIA_MOVIL_3M',\n",
    "    'ROBOS_TOTAL' # Esta será la variable objetivo (Y)\n",
    "]\n",
    "\n",
    "df_model_input = df_model_input[columnas_finales]\n",
    "\n",
    "print(\"--- Vista Preliminar de la Tabla de Entradas (Formato Largo) ---\")\n",
    "print(f\"Total de filas generadas para el modelo: {len(df_model_input)}\")\n",
    "print(\"Ejemplo de las entradas para el CUADRANTE 1:\")\n",
    "print(df_model_input[df_model_input['CUADRANTE_ID'] == 1].head(15))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf269fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar df_model_input a un archivo csv\n",
    "df_model_input.to_csv(\"ficosec_model_input.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4e3fad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exportar df_model_input a un archivo xlsx\n",
    "df_model_input.to_excel(\"ficosec_model_input.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec5a4a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import pandas as pd\n",
    "\n",
    "# Suponiendo que 'df_model_input' es el DataFrame generado en el paso anterior\n",
    "\n",
    "# 1. Identificar las columnas numéricas que necesitan escalado\n",
    "features_to_scale = [\n",
    "    'POBLACION_BASE',\n",
    "    'ROBOS_t-1',\n",
    "    'ROBOS_t-12',\n",
    "    'MEDIA_MOVIL_3M',\n",
    "    # La variable objetivo (Y) también debe escalarse\n",
    "    'ROBOS_TOTAL' \n",
    "]\n",
    "\n",
    "# 2. Inicializar el escalador\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# 3. Aplicar el escalador a las columnas seleccionadas\n",
    "df_model_input[features_to_scale] = scaler.fit_transform(df_model_input[features_to_scale])\n",
    "\n",
    "# Guardar los escaladores si planeas desnormalizar las predicciones más tarde\n",
    "# Por ejemplo, el scaler de ROBOS_TOTAL es crucial para llevar la predicción de vuelta a conteos reales.\n",
    "scaler_robos_total = MinMaxScaler()\n",
    "scaler_robos_total.fit(df_model_input[['ROBOS_TOTAL']]) # Se debe re-entrenar solo en el target si quieres desnormalizar fácilmente\n",
    "\n",
    "print(\"✅ Normalización Min-Max aplicada a las variables numéricas.\")\n",
    "print(df_model_input[features_to_scale].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "803cf3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- A. Codificación One-Hot para el MES ---\n",
    "\n",
    "# Crear variables dummy para la columna 'MES'\n",
    "df_processed = pd.get_dummies(df_model_input, columns=['MES'], prefix='MES')\n",
    "\n",
    "# El CUADRANTE_ID se mantiene como está para el Embedding (se usará directamente en Keras/TensorFlow)\n",
    "\n",
    "print(\"\\n✅ Codificación One-Hot aplicada al MES.\")\n",
    "print(df_processed[[col for col in df_processed.columns if 'MES_' in col]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea64d266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Definir las fechas de corte\n",
    "FECHA_CORTE_VAL = pd.to_datetime('2023-01-01')\n",
    "FECHA_CORTE_TEST = pd.to_datetime('2024-01-01')\n",
    "\n",
    "# 2. Dividir los datos\n",
    "df_train = df_processed[df_processed['FECHA'] < FECHA_CORTE_VAL].copy()\n",
    "df_val = df_processed[(df_processed['FECHA'] >= FECHA_CORTE_VAL) & (df_processed['FECHA'] < FECHA_CORTE_TEST)].copy()\n",
    "df_test = df_processed[df_processed['FECHA'] >= FECHA_CORTE_TEST].copy()\n",
    "\n",
    "# 3. Definición de Entradas (X) y Salidas (Y)\n",
    "features = [\n",
    "    'POBLACION_BASE', \n",
    "    'ROBOS_t-1', \n",
    "    'ROBOS_t-12', \n",
    "    'MEDIA_MOVIL_3M'\n",
    "] + [col for col in df_processed.columns if 'MES_' in col]\n",
    "\n",
    "X_train = df_train[features]\n",
    "Y_train = df_train['ROBOS_TOTAL']\n",
    "\n",
    "X_val = df_val[features]\n",
    "Y_val = df_val['ROBOS_TOTAL']\n",
    "\n",
    "X_test = df_test[features]\n",
    "Y_test = df_test['ROBOS_TOTAL']\n",
    "\n",
    "# El CUADRANTE_ID se manejará como una entrada separada en el modelo de Keras/TensorFlow\n",
    "train_cuadrante_id = df_train['CUADRANTE_ID']\n",
    "val_cuadrante_id = df_val['CUADRANTE_ID']\n",
    "test_cuadrante_id = df_test['CUADRANTE_ID']\n",
    "\n",
    "print(f\"\\n✅ División de datos completada:\")\n",
    "print(f\"  Entrenamiento (Train): {len(X_train)} filas\")\n",
    "print(f\"  Validación (Validation): {len(X_val)} filas\")\n",
    "print(f\"  Prueba (Test): {len(X_test)} filas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a11765f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
    "\n",
    "# --- CONSTANTES ---\n",
    "NUM_CUADRANTES = df_model_input['CUADRANTE_ID'].nunique() # Debería ser 78\n",
    "# La dimensión del embedding debe ser menor que el número de categorías. \n",
    "# Una regla empírica simple es tomar la raíz cuadrada del número de categorías.\n",
    "EMBEDDING_DIM = int(np.sqrt(NUM_CUADRANTES)) # Ej: sqrt(78) ~ 8 o 9. Usemos 10.\n",
    "EMBEDDING_DIM = 10\n",
    "NUM_FEAT_NUMERICAS = X_train.shape[1] \n",
    "\n",
    "# --- CONVERSIÓN A ARRAYS DE NUMPY ---\n",
    "\n",
    "# 1. Entradas para el Embedding (CUADRANTE_ID)\n",
    "# Keras requiere que los IDs empiecen en 0 o 1. Usaremos 1 a N.\n",
    "# NOTA: Los DataFrames 'train_cuadrante_id', 'val_cuadrante_id', 'test_cuadrante_id'\n",
    "# ya están preparados para esto (valores de 1 a 78).\n",
    "X_cuadrante_train = train_cuadrante_id.values\n",
    "X_cuadrante_val = val_cuadrante_id.values\n",
    "X_cuadrante_test = test_cuadrante_id.values\n",
    "\n",
    "# 2. Entradas para las Características Numéricas (Robos t-1, Mes_1, etc.)\n",
    "X_num_train = X_train.values\n",
    "X_num_val = X_val.values\n",
    "X_num_test = X_test.values\n",
    "\n",
    "# 3. Salidas (Objetivo)\n",
    "Y_train = Y_train.values\n",
    "Y_val = Y_val.values\n",
    "Y_test = Y_test.values\n",
    "\n",
    "print(f\"Número de Cuadrantes (Categorías): {NUM_CUADRANTES}\")\n",
    "print(f\"Dimensión del Vector de Embedding: {EMBEDDING_DIM}\")\n",
    "print(f\"Número de Características Numéricas/One-Hot: {NUM_FEAT_NUMERICAS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80208a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Rama de Entrada para el CUADRANTE_ID (Embedding Layer) ---\n",
    "\n",
    "# Input: Un array de números enteros (IDs de 1 a 78)\n",
    "input_cuadrante = Input(shape=(1,), name='input_cuadrante')\n",
    "\n",
    "# Embedding: Convierte cada ID de cuadrante en un vector denso (ej: 78x10)\n",
    "# input_dim: Rango de los IDs (78 cuadrantes + 1 por convención)\n",
    "# output_dim: La dimensión de nuestro vector de embedding (10)\n",
    "embedding_layer = Embedding(\n",
    "    input_dim=NUM_CUADRANTES + 1,\n",
    "    output_dim=EMBEDDING_DIM,\n",
    "    input_length=1,\n",
    "    name='embedding_cuadrante'\n",
    ")(input_cuadrante)\n",
    "\n",
    "# Aplanar el Embedding (de (None, 1, 10) a (None, 10))\n",
    "flatten_embedding = Flatten()(embedding_layer)\n",
    "\n",
    "\n",
    "# --- 2. Rama de Entrada para las Características Numéricas ---\n",
    "\n",
    "# Input: Un array con todas las características (Robos t-1, Mes_1, Población, etc.)\n",
    "input_numerico = Input(shape=(NUM_FEAT_NUMERICAS,), name='input_numerico')\n",
    "\n",
    "\n",
    "# --- 3. Combinación de Ramas (Merging) ---\n",
    "\n",
    "# Concatenar el vector de embedding y las características numéricas\n",
    "combined = Concatenate()([flatten_embedding, input_numerico])\n",
    "\n",
    "# Capas Densa de la Red Neuronal (Deep Layers)\n",
    "# Se utilizan capas profundas para aprender las interacciones complejas.\n",
    "dense_1 = Dense(64, activation='relu')(combined)\n",
    "dense_2 = Dense(32, activation='relu')(dense_1)\n",
    "\n",
    "# Capa de Salida\n",
    "# Output: Un único nodo que predice el valor escalado de ROBOS_TOTAL (Y).\n",
    "output_layer = Dense(1, activation='linear', name='prediccion_final')(dense_2)\n",
    "\n",
    "\n",
    "# --- 4. Crear el Modelo Final ---\n",
    "\n",
    "model = Model(inputs=[input_cuadrante, input_numerico], outputs=output_layer)\n",
    "\n",
    "# Compilación: Usamos 'mean_squared_error' (MSE) para regresión y Adam como optimizador.\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c271f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- CÓDIGO DE VERIFICACIÓN Y CORRECCIÓN DE TIPOS (Solución al ValueError) ---\n",
    "\n",
    "# 1. Identificar todas las columnas que deberían ser numéricas (inputs y targets)\n",
    "numerical_and_target_cols = [\n",
    "    'POBLACION_BASE',\n",
    "    'ROBOS_t-1',\n",
    "    'ROBOS_t-12',\n",
    "    'MEDIA_MOVIL_3M',\n",
    "    'ROBOS_TOTAL'\n",
    "]\n",
    "\n",
    "# 2. Forzar la conversión de estas columnas a numérico (float)\n",
    "# El argumento 'coerce' convierte cualquier valor no numérico (texto) a NaN.\n",
    "for col in numerical_and_target_cols:\n",
    "    df_model_input[col] = pd.to_numeric(df_model_input[col], errors='coerce')\n",
    "\n",
    "# 3. Eliminar o Rellenar los valores NaN que se generaron\n",
    "# Es más seguro eliminar las filas donde esto ocurre, aunque deberían ser pocas.\n",
    "# Si el error ocurrió en una fila crítica (ej. ROBOS_TOTAL), la fila es inutilizable.\n",
    "filas_antes = len(df_model_input)\n",
    "df_model_input.dropna(subset=numerical_and_target_cols, inplace=True)\n",
    "filas_despues = len(df_model_input)\n",
    "\n",
    "if filas_antes != filas_despues:\n",
    "    print(f\"⚠️ Alerta: Se eliminaron {filas_antes - filas_despues} filas debido a valores no numéricos ocultos.\")\n",
    "\n",
    "# 4. Asegurar que las columnas de ID sean Enteros (para el Embedding)\n",
    "# El Embedding Layer requiere IDs enteros.\n",
    "df_model_input['CUADRANTE_ID'] = df_model_input['CUADRANTE_ID'].astype(np.int32)\n",
    "df_model_input['MES'] = df_model_input['MES'].astype(np.int32) \n",
    "\n",
    "print(\"\\n✅ Verificación de tipos de datos completada. Todos los inputs/outputs numéricos están limpios.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d2ddf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_num_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47859dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir X_num_train a float32\n",
    "X_num_train = X_num_train.astype(np.int32)\n",
    "X_num_test = X_num_test.astype(np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "470d302f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_cuadrante_train.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947ffe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convertir X_cuadrante_train a float64\n",
    "X_cuadrante_train = X_cuadrante_train.astype(np.float64)\n",
    "X_cuadrante_test = X_cuadrante_test.astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9210557",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración del entrenamiento\n",
    "history = model.fit(\n",
    "    x=[X_cuadrante_train, X_num_train],\n",
    "    y=Y_train,\n",
    "    validation_data=([X_cuadrante_val, X_num_val], Y_val),\n",
    "    epochs=50, # Puedes empezar con 50 o 100 épocas\n",
    "    batch_size=32,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\n✅ Entrenamiento del Modelo de Red Neuronal Finalizado.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8b3d48b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88774183",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c8f41ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904c5901",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59efee1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b27fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- COMENZANDO ENTRENAMIENTO (Poisson Loss) ---\n",
      "El modelo ahora entrena con valores de conteo originales.\n",
      "Epoch 1/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.4836 - mae: 1.1007 - val_loss: 0.6427 - val_mae: 0.9521\n",
      "Epoch 2/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3688 - mae: 1.0077 - val_loss: 0.6110 - val_mae: 0.9030\n",
      "Epoch 3/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3564 - mae: 0.9962 - val_loss: 0.6502 - val_mae: 0.9847\n",
      "Epoch 4/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3544 - mae: 0.9935 - val_loss: 0.6385 - val_mae: 0.9580\n",
      "Epoch 5/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3518 - mae: 0.9954 - val_loss: 0.6204 - val_mae: 0.9294\n",
      "Epoch 6/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3502 - mae: 0.9906 - val_loss: 0.6255 - val_mae: 0.9313\n",
      "Epoch 7/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3451 - mae: 0.9853 - val_loss: 0.6341 - val_mae: 0.9481\n",
      "Epoch 8/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3433 - mae: 0.9838 - val_loss: 0.6218 - val_mae: 0.9233\n",
      "Epoch 9/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3378 - mae: 0.9808 - val_loss: 0.6405 - val_mae: 0.9594\n",
      "Epoch 10/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3354 - mae: 0.9787 - val_loss: 0.6379 - val_mae: 0.9657\n",
      "Epoch 11/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3336 - mae: 0.9801 - val_loss: 0.6424 - val_mae: 0.9634\n",
      "Epoch 12/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3290 - mae: 0.9732 - val_loss: 0.6512 - val_mae: 0.9829\n",
      "Epoch 13/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3261 - mae: 0.9693 - val_loss: 0.6481 - val_mae: 0.9743\n",
      "Epoch 14/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3205 - mae: 0.9664 - val_loss: 0.6797 - val_mae: 1.0270\n",
      "Epoch 15/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3174 - mae: 0.9638 - val_loss: 0.6580 - val_mae: 0.9861\n",
      "Epoch 16/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3139 - mae: 0.9605 - val_loss: 0.6754 - val_mae: 1.0117\n",
      "Epoch 17/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.3117 - mae: 0.9566 - val_loss: 0.6605 - val_mae: 0.9664\n",
      "Epoch 18/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3077 - mae: 0.9524 - val_loss: 0.6737 - val_mae: 1.0074\n",
      "Epoch 19/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3015 - mae: 0.9502 - val_loss: 0.6688 - val_mae: 0.9709\n",
      "Epoch 20/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2971 - mae: 0.9409 - val_loss: 0.6891 - val_mae: 1.0180\n",
      "Epoch 21/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2942 - mae: 0.9424 - val_loss: 0.6857 - val_mae: 1.0048\n",
      "Epoch 22/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2912 - mae: 0.9416 - val_loss: 0.6594 - val_mae: 0.9589\n",
      "Epoch 23/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2892 - mae: 0.9397 - val_loss: 0.6856 - val_mae: 0.9864\n",
      "Epoch 24/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2847 - mae: 0.9331 - val_loss: 0.6910 - val_mae: 0.9966\n",
      "Epoch 25/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2819 - mae: 0.9282 - val_loss: 0.6857 - val_mae: 1.0028\n",
      "Epoch 26/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2783 - mae: 0.9281 - val_loss: 0.6972 - val_mae: 1.0152\n",
      "Epoch 27/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2744 - mae: 0.9214 - val_loss: 0.7113 - val_mae: 1.0343\n",
      "Epoch 28/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2724 - mae: 0.9185 - val_loss: 0.7200 - val_mae: 1.0475\n",
      "Epoch 29/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2662 - mae: 0.9131 - val_loss: 0.7245 - val_mae: 1.0537\n",
      "Epoch 30/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2679 - mae: 0.9176 - val_loss: 0.7009 - val_mae: 0.9927\n",
      "Epoch 31/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2625 - mae: 0.9059 - val_loss: 0.7416 - val_mae: 1.0747\n",
      "Epoch 32/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2604 - mae: 0.9044 - val_loss: 0.7093 - val_mae: 1.0203\n",
      "Epoch 33/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2574 - mae: 0.9054 - val_loss: 0.7094 - val_mae: 1.0129\n",
      "Epoch 34/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2537 - mae: 0.8989 - val_loss: 0.7197 - val_mae: 1.0214\n",
      "Epoch 35/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2532 - mae: 0.8950 - val_loss: 0.7585 - val_mae: 1.0771\n",
      "Epoch 36/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2463 - mae: 0.8886 - val_loss: 0.7149 - val_mae: 1.0115\n",
      "Epoch 37/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2422 - mae: 0.8855 - val_loss: 0.7260 - val_mae: 1.0088\n",
      "Epoch 38/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2413 - mae: 0.8820 - val_loss: 0.7185 - val_mae: 1.0060\n",
      "Epoch 39/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2391 - mae: 0.8782 - val_loss: 0.7320 - val_mae: 0.9975\n",
      "Epoch 40/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2328 - mae: 0.8733 - val_loss: 0.7244 - val_mae: 1.0125\n",
      "Epoch 41/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2267 - mae: 0.8668 - val_loss: 0.7300 - val_mae: 1.0200\n",
      "Epoch 42/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2262 - mae: 0.8651 - val_loss: 0.7516 - val_mae: 1.0412\n",
      "Epoch 43/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2224 - mae: 0.8620 - val_loss: 0.7544 - val_mae: 1.0289\n",
      "Epoch 44/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2159 - mae: 0.8521 - val_loss: 0.7698 - val_mae: 1.0371\n",
      "Epoch 45/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2140 - mae: 0.8521 - val_loss: 0.7705 - val_mae: 1.0577\n",
      "Epoch 46/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2084 - mae: 0.8452 - val_loss: 0.7701 - val_mae: 1.0468\n",
      "Epoch 47/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.2058 - mae: 0.8406 - val_loss: 0.7552 - val_mae: 1.0417\n",
      "Epoch 48/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2003 - mae: 0.8320 - val_loss: 0.7774 - val_mae: 1.0314\n",
      "Epoch 49/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1953 - mae: 0.8280 - val_loss: 0.7815 - val_mae: 1.0639\n",
      "Epoch 50/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1918 - mae: 0.8226 - val_loss: 0.8019 - val_mae: 1.0783\n",
      "Epoch 51/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.1907 - mae: 0.8223 - val_loss: 0.8232 - val_mae: 1.0944\n",
      "Epoch 52/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1833 - mae: 0.8135 - val_loss: 0.7826 - val_mae: 1.0749\n",
      "Epoch 53/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1784 - mae: 0.8053 - val_loss: 0.8224 - val_mae: 1.0658\n",
      "Epoch 54/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1755 - mae: 0.8035 - val_loss: 0.7910 - val_mae: 1.0689\n",
      "Epoch 55/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1711 - mae: 0.7989 - val_loss: 0.7952 - val_mae: 1.0696\n",
      "Epoch 56/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1670 - mae: 0.7929 - val_loss: 0.8440 - val_mae: 1.1014\n",
      "Epoch 57/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1635 - mae: 0.7882 - val_loss: 0.8484 - val_mae: 1.0833\n",
      "Epoch 58/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1566 - mae: 0.7802 - val_loss: 0.8491 - val_mae: 1.0980\n",
      "Epoch 59/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1539 - mae: 0.7774 - val_loss: 0.8420 - val_mae: 1.0844\n",
      "Epoch 60/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1500 - mae: 0.7733 - val_loss: 0.8730 - val_mae: 1.0684\n",
      "Epoch 61/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1442 - mae: 0.7618 - val_loss: 0.8298 - val_mae: 1.0849\n",
      "Epoch 62/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1410 - mae: 0.7577 - val_loss: 0.8995 - val_mae: 1.0871\n",
      "Epoch 63/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1378 - mae: 0.7569 - val_loss: 0.8530 - val_mae: 1.0489\n",
      "Epoch 64/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1309 - mae: 0.7455 - val_loss: 0.8738 - val_mae: 1.0964\n",
      "Epoch 65/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1290 - mae: 0.7459 - val_loss: 0.9129 - val_mae: 1.0968\n",
      "Epoch 66/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1294 - mae: 0.7466 - val_loss: 0.9093 - val_mae: 1.1124\n",
      "Epoch 67/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1183 - mae: 0.7305 - val_loss: 0.9048 - val_mae: 1.0947\n",
      "Epoch 68/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1184 - mae: 0.7285 - val_loss: 0.9364 - val_mae: 1.1360\n",
      "Epoch 69/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1127 - mae: 0.7222 - val_loss: 0.9293 - val_mae: 1.1351\n",
      "Epoch 70/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1103 - mae: 0.7207 - val_loss: 0.9118 - val_mae: 1.1232\n",
      "Epoch 71/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1076 - mae: 0.7135 - val_loss: 0.9296 - val_mae: 1.1561\n",
      "Epoch 72/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1019 - mae: 0.7110 - val_loss: 0.9863 - val_mae: 1.1550\n",
      "Epoch 73/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0992 - mae: 0.7037 - val_loss: 0.9830 - val_mae: 1.0992\n",
      "Epoch 74/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0979 - mae: 0.7027 - val_loss: 0.9599 - val_mae: 1.1163\n",
      "Epoch 75/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0966 - mae: 0.7013 - val_loss: 0.9872 - val_mae: 1.1236\n",
      "Epoch 76/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0879 - mae: 0.6903 - val_loss: 0.9780 - val_mae: 1.1334\n",
      "Epoch 77/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0864 - mae: 0.6889 - val_loss: 0.9442 - val_mae: 1.1289\n",
      "Epoch 78/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0834 - mae: 0.6836 - val_loss: 1.0144 - val_mae: 1.1536\n",
      "Epoch 79/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0797 - mae: 0.6827 - val_loss: 1.0354 - val_mae: 1.0898\n",
      "Epoch 80/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0810 - mae: 0.6845 - val_loss: 0.9713 - val_mae: 1.1066\n",
      "Epoch 81/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0724 - mae: 0.6686 - val_loss: 1.0828 - val_mae: 1.1105\n",
      "Epoch 82/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0705 - mae: 0.6681 - val_loss: 1.0664 - val_mae: 1.1335\n",
      "Epoch 83/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0710 - mae: 0.6670 - val_loss: 1.0952 - val_mae: 1.1199\n",
      "Epoch 84/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0661 - mae: 0.6598 - val_loss: 1.0658 - val_mae: 1.1604\n",
      "Epoch 85/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0659 - mae: 0.6636 - val_loss: 1.0288 - val_mae: 1.1081\n",
      "Epoch 86/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0588 - mae: 0.6504 - val_loss: 1.0122 - val_mae: 1.1448\n",
      "Epoch 87/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0574 - mae: 0.6506 - val_loss: 1.0008 - val_mae: 1.1569\n",
      "Epoch 88/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0559 - mae: 0.6430 - val_loss: 1.0745 - val_mae: 1.1528\n",
      "Epoch 89/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0514 - mae: 0.6410 - val_loss: 1.1366 - val_mae: 1.1263\n",
      "Epoch 90/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0501 - mae: 0.6390 - val_loss: 1.0667 - val_mae: 1.1149\n",
      "Epoch 91/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0468 - mae: 0.6344 - val_loss: 1.1206 - val_mae: 1.1172\n",
      "Epoch 92/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0426 - mae: 0.6284 - val_loss: 1.1014 - val_mae: 1.1548\n",
      "Epoch 93/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0407 - mae: 0.6241 - val_loss: 1.1236 - val_mae: 1.1392\n",
      "Epoch 94/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0424 - mae: 0.6280 - val_loss: 1.0967 - val_mae: 1.1636\n",
      "Epoch 95/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0338 - mae: 0.6175 - val_loss: 1.1086 - val_mae: 1.1434\n",
      "Epoch 96/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0334 - mae: 0.6153 - val_loss: 1.1373 - val_mae: 1.1390\n",
      "Epoch 97/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0319 - mae: 0.6138 - val_loss: 1.0920 - val_mae: 1.1414\n",
      "Epoch 98/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - loss: 0.0288 - mae: 0.6077 - val_loss: 1.1051 - val_mae: 1.1298\n",
      "Epoch 99/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0283 - mae: 0.6084 - val_loss: 1.1471 - val_mae: 1.1354\n",
      "Epoch 100/100\n",
      "\u001b[1m410/410\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0232 - mae: 0.6048 - val_loss: 1.2067 - val_mae: 1.1182\n",
      "✅ Entrenamiento del Modelo de Red Neuronal Finalizado.\n",
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten\n",
    "from tensorflow.keras.losses import Poisson\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# --- CONFIGURACIÓN Y CONSTANTES ---\n",
    "# Asegúrate de que este sea el nombre de tu archivo\n",
    "FILE_NAME = \"cuadrantes_negocios.csv\" \n",
    "NUM_CUADRANTES = 78\n",
    "EMBEDDING_DIM = 10 \n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# --- 1. CARGA, TRANSFORMACIÓN (ANCHO A LARGO) Y GENERACIÓN DE FEATURES ---\n",
    "\n",
    "def load_and_prepare_data(file_name):\n",
    "    \"\"\"Carga, transforma el formato ancho a largo y genera features de retardo.\"\"\"\n",
    "    try:\n",
    "        df_wide = pd.read_csv(file_name)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró el archivo '{file_name}'.\")\n",
    "        raise\n",
    "\n",
    "    df_wide.rename(columns={'CUADRANTE': 'CUADRANTE_ID', 'POBLACION': 'POBLACION_BASE'}, inplace=True)\n",
    "    \n",
    "    id_vars = ['CUADRANTE_ID', 'POBLACION_BASE']\n",
    "    value_vars = [col for col in df_wide.columns if col not in id_vars]\n",
    "\n",
    "    # Transformación de Ancho a Largo (Melt)\n",
    "    df_long = df_wide.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name='MES_AÑO_STR',\n",
    "        value_name='ROBOS_TOTAL'\n",
    "    ).copy()\n",
    "\n",
    "    # Parsear la fecha\n",
    "    def parse_date(date_str):\n",
    "        parts = date_str.split(' ')\n",
    "        # Asumiendo el formato 'ROBOS A NEGOCIOS MES 1 2015'\n",
    "        mes = parts[4] \n",
    "        año = parts[5] \n",
    "        return f'{año}-{mes}-01'\n",
    "\n",
    "    df_long['FECHA'] = df_long['MES_AÑO_STR'].apply(parse_date)\n",
    "    df_long['FECHA'] = pd.to_datetime(df_long['FECHA'])\n",
    "    df_long.sort_values(by=['CUADRANTE_ID', 'FECHA'], inplace=True)\n",
    "    df_long.drop(columns=['MES_AÑO_STR'], inplace=True)\n",
    "\n",
    "    # Generación de Características Temporales y Retardos\n",
    "    df_long['AÑO'] = df_long['FECHA'].dt.year\n",
    "    df_long['MES'] = df_long['FECHA'].dt.month\n",
    "    df_long['ROBOS_t-1'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].shift(1)\n",
    "    df_long['ROBOS_t-12'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].shift(12)\n",
    "    df_long['MEDIA_MOVIL_3M'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True).shift(1)\n",
    "    \n",
    "    # Eliminar filas con NaN en los retardos (primeros 12 meses)\n",
    "    df_model_input = df_long.dropna(subset=['ROBOS_t-12']).copy()\n",
    "    \n",
    "    return df_model_input\n",
    "\n",
    "# Cargar y preparar los datos\n",
    "df_model_input = load_and_prepare_data(FILE_NAME)\n",
    "\n",
    "\n",
    "# --- 2. LIMPIEZA, NORMALIZACIÓN (SOLO FEATURES) Y CODIFICACIÓN ---\n",
    "\n",
    "# 2.1. Verificación y Corrección de Tipos (Limpieza de \"object\")\n",
    "numerical_and_target_cols = ['POBLACION_BASE', 'ROBOS_t-1', 'ROBOS_t-12', 'MEDIA_MOVIL_3M', 'ROBOS_TOTAL']\n",
    "for col in numerical_and_target_cols:\n",
    "    df_model_input[col] = pd.to_numeric(df_model_input[col], errors='coerce')\n",
    "\n",
    "df_model_input.dropna(subset=numerical_and_target_cols, inplace=True)\n",
    "df_model_input['CUADRANTE_ID'] = df_model_input['CUADRANTE_ID'].astype(np.int32)\n",
    "df_model_input['MES'] = df_model_input['MES'].astype(np.int32)\n",
    "\n",
    "# 2.2. Normalización Min-Max (¡SOLO VARIABLES DE ENTRADA/FEATURES!)\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = ['POBLACION_BASE', 'ROBOS_t-1', 'ROBOS_t-12', 'MEDIA_MOVIL_3M']\n",
    "\n",
    "# El target 'ROBOS_TOTAL' NO se normaliza para la Pérdida de Poisson.\n",
    "df_model_input[features_to_scale] = scaler.fit_transform(df_model_input[features_to_scale])\n",
    "\n",
    "# 2.3. Codificación One-Hot para el MES\n",
    "df_processed = pd.get_dummies(df_model_input, columns=['MES'], prefix='MES')\n",
    "\n",
    "\n",
    "# --- 3. DIVISIÓN DE DATOS Y PREPARACIÓN DE ARRAYS ---\n",
    "\n",
    "FECHA_CORTE_VAL = pd.to_datetime('2023-01-01')\n",
    "FECHA_CORTE_TEST = pd.to_datetime('2024-01-01')\n",
    "\n",
    "# División\n",
    "df_train = df_processed[df_processed['FECHA'] < FECHA_CORTE_VAL]\n",
    "df_val = df_processed[(df_processed['FECHA'] >= FECHA_CORTE_VAL) & (df_processed['FECHA'] < FECHA_CORTE_TEST)]\n",
    "df_test = df_processed[df_processed['FECHA'] >= FECHA_CORTE_TEST]\n",
    "\n",
    "# Definición de Features para la rama numérica\n",
    "features = features_to_scale + [col for col in df_processed.columns if 'MES_' in col]\n",
    "\n",
    "\n",
    "# Conversión a Arrays de NumPy con tipo explícito\n",
    "X_cuadrante_train = df_train['CUADRANTE_ID'].values.astype(np.int32)\n",
    "X_cuadrante_val = df_val['CUADRANTE_ID'].values.astype(np.int32)\n",
    "X_cuadrante_test = df_test['CUADRANTE_ID'].values.astype(np.int32)\n",
    "\n",
    "X_num_train = df_train[features].values.astype(np.float32)\n",
    "X_num_val = df_val[features].values.astype(np.float32)\n",
    "X_num_test = df_test[features].values.astype(np.float32)\n",
    "\n",
    "# Y_train usa el valor de conteo original (CORRECCIÓN CRÍTICA)\n",
    "Y_train = df_train['ROBOS_TOTAL'].values.astype(np.float32)\n",
    "Y_val = df_val['ROBOS_TOTAL'].values.astype(np.float32)\n",
    "Y_test = df_test['ROBOS_TOTAL'].values.astype(np.float32)\n",
    "\n",
    "\n",
    "# --- 4. CONSTRUCCIÓN Y ENTRENAMIENTO DEL MODELO DE RED NEURONAL ---\n",
    "\n",
    "def build_model(num_cuadrantes, embedding_dim, num_feat_numericas):\n",
    "    \n",
    "    # 1. Rama Embedding\n",
    "    input_cuadrante = Input(shape=(1,), name='input_cuadrante')\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=num_cuadrantes + 1, \n",
    "        output_dim=embedding_dim,\n",
    "        input_length=1,\n",
    "        name='embedding_cuadrante'\n",
    "    )(input_cuadrante)\n",
    "    flatten_embedding = Flatten()(embedding_layer)\n",
    "\n",
    "    # 2. Rama Numérica\n",
    "    input_numerico = Input(shape=(num_feat_numericas,), name='input_numerico')\n",
    "\n",
    "    # 3. Concatenación y Capas Profundas (AUMENTADAS)\n",
    "    combined = Concatenate()([flatten_embedding, input_numerico])\n",
    "    \n",
    "    # Capas Ocultas con mayor capacidad\n",
    "    dense_1 = Dense(128, activation='relu')(combined) \n",
    "    dense_2 = Dense(64, activation='relu')(dense_1)   \n",
    "    dense_3 = Dense(32, activation='relu')(dense_2)   \n",
    "    \n",
    "    # 4. Capa de Salida: SOFTPLUS para asegurar predicciones NO NEGATIVAS.\n",
    "    output_layer = Dense(1, activation='softplus', name='prediccion_final')(dense_3)\n",
    "\n",
    "    model = Model(inputs=[input_cuadrante, input_numerico], outputs=output_layer)\n",
    "    \n",
    "    # Compilación: LOSS POISSON para datos de conteo.\n",
    "    model.compile(optimizer='adam', loss=Poisson(), metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model(NUM_CUADRANTES, EMBEDDING_DIM, X_num_train.shape[1])\n",
    "\n",
    "# 4.2. Entrenamiento\n",
    "print(\"\\n--- COMENZANDO ENTRENAMIENTO (Poisson Loss) ---\")\n",
    "print(\"El modelo ahora entrena con valores de conteo originales.\")\n",
    "\n",
    "history = model.fit(\n",
    "    x=[X_cuadrante_train, X_num_train],\n",
    "    y=Y_train,\n",
    "    validation_data=([X_cuadrante_val, X_num_val], Y_val),\n",
    "    epochs=EPOCHS, \n",
    "    batch_size=BATCH_SIZE, \n",
    "    verbose=1\n",
    ")\n",
    "print(\"✅ Entrenamiento del Modelo de Red Neuronal Finalizado.\")\n",
    "\n",
    "\n",
    "# --- 5. PREDICCIÓN FINAL (Ejemplo para Enero 2024) ---\n",
    "\n",
    "# 5.1. Predicción: El resultado ya está en la escala de conteo real.\n",
    "y_pred_real = model.predict([X_cuadrante_test, X_num_test])\n",
    "\n",
    "# 5.2. Formatear las 78 Salidas\n",
    "df_results = pd.DataFrame({\n",
    "    'CUADRANTE_ID': df_test['CUADRANTE_ID'].values,\n",
    "    'FECHA': df_test['FECHA'].values,\n",
    "    # La predicción ya es el conteo real, solo se redondea.\n",
    "    'PREDICCION_ROBOS_REAL': y_pred_real.flatten()\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c39650b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- TOP 10 CUADRANTES CON MAYOR INCIDENCIA (Predicción para Enero 2024) ---\n",
      "     CUADRANTE_ID  PREDICCION_ROBOS_REAL\n",
      "432            37                      6\n",
      "288            25                      6\n",
      "144            13                      5\n",
      "816            69                      5\n",
      "252            22                      4\n",
      "648            55                      4\n",
      "828            70                      4\n",
      "360            31                      3\n",
      "324            28                      3\n",
      "336            29                      3\n"
     ]
    }
   ],
   "source": [
    "# Filtrar un mes específico y ordenar (ej: Enero 2024)\n",
    "MES_A_EVALUAR = 1\n",
    "prediccion_enero = df_results[df_results['FECHA'].dt.month == MES_A_EVALUAR].copy()\n",
    "prediccion_enero['PREDICCION_ROBOS_REAL'] = prediccion_enero['PREDICCION_ROBOS_REAL'].round(0).astype(int)\n",
    "prediccion_enero = prediccion_enero.sort_values(by='PREDICCION_ROBOS_REAL', ascending=False)\n",
    "\n",
    "\n",
    "print(f\"\\n--- TOP 10 CUADRANTES CON MAYOR INCIDENCIA (Predicción para Enero 2024) ---\")\n",
    "print(prediccion_enero[['CUADRANTE_ID', 'PREDICCION_ROBOS_REAL']].head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a5936a7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Comparación de Robos a Negocio: 1/2024 ---\n",
      "Ordenado por la Predicción (Mayor Riesgo)\n",
      "|   CUADRANTE_ID |   ROBOS_REAL |   PREDICCION_ROBOS_REAL |   ERROR (Real - Pred) |\n",
      "|---------------:|-------------:|------------------------:|----------------------:|\n",
      "|             37 |            3 |                       6 |                    -3 |\n",
      "|             25 |            2 |                       6 |                    -4 |\n",
      "|             13 |            6 |                       5 |                     1 |\n",
      "|             69 |            0 |                       5 |                    -5 |\n",
      "|             22 |            5 |                       4 |                     1 |\n",
      "|             55 |            8 |                       4 |                     4 |\n",
      "|             70 |            4 |                       4 |                     0 |\n",
      "|             31 |            2 |                       3 |                    -1 |\n",
      "|             28 |            0 |                       3 |                    -3 |\n",
      "|             29 |            0 |                       3 |                    -3 |\n",
      "|             11 |            3 |                       2 |                     1 |\n",
      "|             24 |            2 |                       2 |                     0 |\n",
      "|             48 |            2 |                       2 |                     0 |\n",
      "|              6 |            1 |                       2 |                    -1 |\n",
      "|             27 |            0 |                       2 |                    -2 |\n",
      "|             75 |            1 |                       2 |                    -1 |\n",
      "|             56 |            2 |                       1 |                     1 |\n",
      "|             54 |            0 |                       1 |                    -1 |\n",
      "|             47 |            2 |                       1 |                     1 |\n",
      "|             77 |            6 |                       1 |                     5 |\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Preparación de los datos reales (Y_test) ---\n",
    "\n",
    "# Aseguramos que Y_test use el valor de conteo original.\n",
    "# Nota: Y_test se definió como df_test['ROBOS_TOTAL'].values.astype(np.float32)\n",
    "# Esto se hizo antes del entrenamiento, por lo que ya contiene los valores REALES.\n",
    "\n",
    "# Creamos una columna con los valores reales del conjunto de prueba.\n",
    "df_test['ROBOS_REAL'] = Y_test \n",
    "\n",
    "\n",
    "# --- 2. Formato de la Tabla de Resultados ---\n",
    "\n",
    "# df_results fue generado en el paso anterior y contiene:\n",
    "# ['CUADRANTE_ID', 'FECHA', 'PREDICCION_ROBOS_REAL']\n",
    "\n",
    "# Unimos los resultados de la predicción con los valores reales\n",
    "df_comparacion = df_results.merge(\n",
    "    df_test[['CUADRANTE_ID', 'FECHA', 'ROBOS_REAL']], \n",
    "    on=['CUADRANTE_ID', 'FECHA'], \n",
    "    how='left'\n",
    ").copy()\n",
    "\n",
    "# Redondear y asegurar que los conteos sean enteros\n",
    "df_comparacion['PREDICCION_ROBOS_REAL'] = df_comparacion['PREDICCION_ROBOS_REAL'].round(0).astype(int)\n",
    "df_comparacion['ROBOS_REAL'] = df_comparacion['ROBOS_REAL'].round(0).astype(int)\n",
    "\n",
    "# --- 3. Filtrar para Enero de 2024 y Mostrar ---\n",
    "\n",
    "MES_A_EVALUAR = 1\n",
    "AÑO_A_EVALUAR = 2024\n",
    "\n",
    "df_enero_2024 = df_comparacion[\n",
    "    (df_comparacion['FECHA'].dt.month == MES_A_EVALUAR) & \n",
    "    (df_comparacion['FECHA'].dt.year == AÑO_A_EVALUAR)\n",
    "].sort_values(by='PREDICCION_ROBOS_REAL', ascending=False).reset_index(drop=True)\n",
    "\n",
    "# Añadir la diferencia (Error)\n",
    "df_enero_2024['ERROR (Real - Pred)'] = df_enero_2024['ROBOS_REAL'] - df_enero_2024['PREDICCION_ROBOS_REAL']\n",
    "\n",
    "# Seleccionar y mostrar las columnas clave\n",
    "df_final = df_enero_2024[['CUADRANTE_ID', 'ROBOS_REAL', 'PREDICCION_ROBOS_REAL', 'ERROR (Real - Pred)']]\n",
    "\n",
    "print(f\"\\n--- Comparación de Robos a Negocio: {MES_A_EVALUAR}/{AÑO_A_EVALUAR} ---\")\n",
    "print(\"Ordenado por la Predicción (Mayor Riesgo)\")\n",
    "\n",
    "# \n",
    "\n",
    "print(df_final.head(20).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0a60f480",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "\n",
      "--- Evaluación del Modelo de Red Neuronal ---\n",
      "Número total de predicciones evaluadas: 936\n",
      "El Coeficiente de Determinación (R^2) en el conjunto de prueba es: -0.1874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "import numpy as np\n",
    "\n",
    "# --- 1. Obtener las predicciones del modelo ---\n",
    "# Nota: Asumimos que X_cuadrante_test y X_num_test ya están definidos y listos.\n",
    "\n",
    "# Predicción en escala de conteo (no normalizada)\n",
    "y_pred_real = model.predict([X_cuadrante_test, X_num_test])\n",
    "\n",
    "# --- 2. Preparar los datos para R2 ---\n",
    "\n",
    "# Y_test es el valor real (conteo, float32)\n",
    "# y_pred_real es el valor predicho (conteo, float32)\n",
    "\n",
    "# Scikit-learn espera arrays 1D. Aplanamos las predicciones.\n",
    "y_true = Y_test \n",
    "y_predicted = y_pred_real.flatten()\n",
    "\n",
    "# Opcional: Redondear a entero para el R2, ya que son conteos (aunque no es estrictamente necesario)\n",
    "# Usaremos el valor flotante para mayor precisión en la métrica:\n",
    "\n",
    "# --- 3. Calcular el R^2 ---\n",
    "\n",
    "# La función r2_score maneja el cálculo R^2\n",
    "r2 = r2_score(y_true, y_predicted)\n",
    "\n",
    "# --- 4. Mostrar el Resultado ---\n",
    "\n",
    "print(\"\\n--- Evaluación del Modelo de Red Neuronal ---\")\n",
    "print(f\"Número total de predicciones evaluadas: {len(y_true)}\")\n",
    "print(f\"El Coeficiente de Determinación (R^2) en el conjunto de prueba es: {r2:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c6450f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 17:04:52.250024: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-11-19 17:05:14.876986: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-11-19 17:05:25.393239: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- COMENZANDO ENTRENAMIENTO DE LA RED NEURONAL LSTM ---\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-19 17:05:34.958107: E external/local_xla/xla/stream_executor/cuda/cuda_platform.cc:51] failed call to cuInit: INTERNAL: CUDA error: Failed call to cuInit: UNKNOWN ERROR (303)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - loss: 0.5037 - mae: 1.1195 - val_loss: 0.7023 - val_mae: 1.0853\n",
      "Epoch 2/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3890 - mae: 1.0330 - val_loss: 0.6190 - val_mae: 0.9660\n",
      "Epoch 3/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3743 - mae: 1.0127 - val_loss: 0.6346 - val_mae: 0.9847\n",
      "Epoch 4/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3704 - mae: 1.0125 - val_loss: 0.6411 - val_mae: 0.9973\n",
      "Epoch 5/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3673 - mae: 1.0120 - val_loss: 0.6195 - val_mae: 0.9480\n",
      "Epoch 6/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3642 - mae: 1.0060 - val_loss: 0.6346 - val_mae: 0.9851\n",
      "Epoch 7/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3653 - mae: 1.0093 - val_loss: 0.6329 - val_mae: 0.9837\n",
      "Epoch 8/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3629 - mae: 1.0065 - val_loss: 0.6375 - val_mae: 0.9876\n",
      "Epoch 9/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3604 - mae: 1.0042 - val_loss: 0.6329 - val_mae: 0.9720\n",
      "Epoch 10/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3610 - mae: 1.0037 - val_loss: 0.6322 - val_mae: 0.9777\n",
      "Epoch 11/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - loss: 0.3592 - mae: 0.9999 - val_loss: 0.6531 - val_mae: 1.0108\n",
      "Epoch 12/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3586 - mae: 1.0015 - val_loss: 0.6648 - val_mae: 1.0345\n",
      "Epoch 13/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3569 - mae: 1.0015 - val_loss: 0.6339 - val_mae: 0.9714\n",
      "Epoch 14/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3550 - mae: 0.9964 - val_loss: 0.6844 - val_mae: 1.0687\n",
      "Epoch 15/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3556 - mae: 1.0011 - val_loss: 0.6268 - val_mae: 0.9607\n",
      "Epoch 16/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3529 - mae: 0.9994 - val_loss: 0.6387 - val_mae: 0.9819\n",
      "Epoch 17/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3492 - mae: 0.9949 - val_loss: 0.6654 - val_mae: 1.0269\n",
      "Epoch 18/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3486 - mae: 0.9925 - val_loss: 0.6497 - val_mae: 0.9899\n",
      "Epoch 19/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 4ms/step - loss: 0.3477 - mae: 0.9932 - val_loss: 0.6567 - val_mae: 1.0085\n",
      "Epoch 20/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - loss: 0.3433 - mae: 0.9876 - val_loss: 0.6401 - val_mae: 0.9688\n",
      "Epoch 21/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3447 - mae: 0.9910 - val_loss: 0.6431 - val_mae: 0.9808\n",
      "Epoch 22/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3422 - mae: 0.9869 - val_loss: 0.6664 - val_mae: 1.0219\n",
      "Epoch 23/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3422 - mae: 0.9853 - val_loss: 0.6611 - val_mae: 1.0151\n",
      "Epoch 24/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3399 - mae: 0.9847 - val_loss: 0.6608 - val_mae: 1.0105\n",
      "Epoch 25/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3398 - mae: 0.9845 - val_loss: 0.6795 - val_mae: 1.0452\n",
      "Epoch 26/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3371 - mae: 0.9825 - val_loss: 0.6655 - val_mae: 1.0136\n",
      "Epoch 27/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3363 - mae: 0.9810 - val_loss: 0.6569 - val_mae: 0.9933\n",
      "Epoch 28/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3340 - mae: 0.9780 - val_loss: 0.6627 - val_mae: 1.0063\n",
      "Epoch 29/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3327 - mae: 0.9761 - val_loss: 0.6512 - val_mae: 0.9812\n",
      "Epoch 30/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3289 - mae: 0.9747 - val_loss: 0.6527 - val_mae: 0.9858\n",
      "Epoch 31/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3280 - mae: 0.9708 - val_loss: 0.6572 - val_mae: 0.9994\n",
      "Epoch 32/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3291 - mae: 0.9739 - val_loss: 0.6744 - val_mae: 1.0340\n",
      "Epoch 33/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3265 - mae: 0.9728 - val_loss: 0.6523 - val_mae: 0.9872\n",
      "Epoch 34/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3254 - mae: 0.9681 - val_loss: 0.6607 - val_mae: 1.0039\n",
      "Epoch 35/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3215 - mae: 0.9659 - val_loss: 0.6698 - val_mae: 1.0111\n",
      "Epoch 36/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3214 - mae: 0.9672 - val_loss: 0.6673 - val_mae: 1.0137\n",
      "Epoch 37/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3172 - mae: 0.9628 - val_loss: 0.7008 - val_mae: 1.0770\n",
      "Epoch 38/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3165 - mae: 0.9604 - val_loss: 0.6658 - val_mae: 0.9999\n",
      "Epoch 39/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3147 - mae: 0.9583 - val_loss: 0.6881 - val_mae: 1.0540\n",
      "Epoch 40/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3124 - mae: 0.9582 - val_loss: 0.6718 - val_mae: 1.0146\n",
      "Epoch 41/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3108 - mae: 0.9583 - val_loss: 0.7027 - val_mae: 1.0778\n",
      "Epoch 42/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3061 - mae: 0.9540 - val_loss: 0.6788 - val_mae: 1.0124\n",
      "Epoch 43/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.3072 - mae: 0.9508 - val_loss: 0.6944 - val_mae: 1.0539\n",
      "Epoch 44/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3045 - mae: 0.9502 - val_loss: 0.6692 - val_mae: 1.0085\n",
      "Epoch 45/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3031 - mae: 0.9490 - val_loss: 0.6694 - val_mae: 1.0012\n",
      "Epoch 46/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.3000 - mae: 0.9467 - val_loss: 0.6892 - val_mae: 1.0287\n",
      "Epoch 47/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2996 - mae: 0.9498 - val_loss: 0.6862 - val_mae: 1.0179\n",
      "Epoch 48/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2969 - mae: 0.9449 - val_loss: 0.7025 - val_mae: 1.0296\n",
      "Epoch 49/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2942 - mae: 0.9415 - val_loss: 0.6891 - val_mae: 1.0080\n",
      "Epoch 50/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2911 - mae: 0.9381 - val_loss: 0.6753 - val_mae: 1.0005\n",
      "Epoch 51/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2941 - mae: 0.9393 - val_loss: 0.7014 - val_mae: 1.0421\n",
      "Epoch 52/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2860 - mae: 0.9321 - val_loss: 0.6931 - val_mae: 1.0190\n",
      "Epoch 53/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2844 - mae: 0.9316 - val_loss: 0.6966 - val_mae: 1.0198\n",
      "Epoch 54/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2844 - mae: 0.9310 - val_loss: 0.6963 - val_mae: 1.0229\n",
      "Epoch 55/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2796 - mae: 0.9250 - val_loss: 0.7081 - val_mae: 1.0383\n",
      "Epoch 56/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2788 - mae: 0.9237 - val_loss: 0.6997 - val_mae: 1.0210\n",
      "Epoch 57/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2766 - mae: 0.9224 - val_loss: 0.6951 - val_mae: 1.0302\n",
      "Epoch 58/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2738 - mae: 0.9219 - val_loss: 0.7094 - val_mae: 1.0314\n",
      "Epoch 59/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2721 - mae: 0.9172 - val_loss: 0.7057 - val_mae: 1.0418\n",
      "Epoch 60/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2696 - mae: 0.9133 - val_loss: 0.7102 - val_mae: 1.0383\n",
      "Epoch 61/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2664 - mae: 0.9128 - val_loss: 0.7060 - val_mae: 1.0261\n",
      "Epoch 62/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2657 - mae: 0.9140 - val_loss: 0.7072 - val_mae: 1.0367\n",
      "Epoch 63/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2625 - mae: 0.9134 - val_loss: 0.7151 - val_mae: 1.0303\n",
      "Epoch 64/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2609 - mae: 0.9062 - val_loss: 0.7245 - val_mae: 1.0482\n",
      "Epoch 65/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2575 - mae: 0.9041 - val_loss: 0.7372 - val_mae: 1.0739\n",
      "Epoch 66/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2540 - mae: 0.8995 - val_loss: 0.7511 - val_mae: 1.0726\n",
      "Epoch 67/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2513 - mae: 0.8928 - val_loss: 0.7421 - val_mae: 1.0808\n",
      "Epoch 68/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2529 - mae: 0.8961 - val_loss: 0.7467 - val_mae: 1.0734\n",
      "Epoch 69/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2488 - mae: 0.8898 - val_loss: 0.7255 - val_mae: 1.0562\n",
      "Epoch 70/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2433 - mae: 0.8883 - val_loss: 0.7408 - val_mae: 1.0397\n",
      "Epoch 71/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2439 - mae: 0.8874 - val_loss: 0.7437 - val_mae: 1.0619\n",
      "Epoch 72/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2423 - mae: 0.8844 - val_loss: 0.7547 - val_mae: 1.0768\n",
      "Epoch 73/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2388 - mae: 0.8807 - val_loss: 0.7472 - val_mae: 1.0733\n",
      "Epoch 74/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2351 - mae: 0.8738 - val_loss: 0.7357 - val_mae: 1.0536\n",
      "Epoch 75/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2336 - mae: 0.8745 - val_loss: 0.7533 - val_mae: 1.0748\n",
      "Epoch 76/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2306 - mae: 0.8715 - val_loss: 0.7438 - val_mae: 1.0516\n",
      "Epoch 77/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2313 - mae: 0.8732 - val_loss: 0.7602 - val_mae: 1.0555\n",
      "Epoch 78/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2241 - mae: 0.8621 - val_loss: 0.7462 - val_mae: 1.0595\n",
      "Epoch 79/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2208 - mae: 0.8583 - val_loss: 0.7643 - val_mae: 1.0448\n",
      "Epoch 80/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2176 - mae: 0.8556 - val_loss: 0.7742 - val_mae: 1.0627\n",
      "Epoch 81/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2178 - mae: 0.8540 - val_loss: 0.7608 - val_mae: 1.0540\n",
      "Epoch 82/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2183 - mae: 0.8560 - val_loss: 0.7606 - val_mae: 1.0943\n",
      "Epoch 83/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2139 - mae: 0.8486 - val_loss: 0.7650 - val_mae: 1.0827\n",
      "Epoch 84/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2088 - mae: 0.8468 - val_loss: 0.7737 - val_mae: 1.0816\n",
      "Epoch 85/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2098 - mae: 0.8471 - val_loss: 0.7632 - val_mae: 1.0581\n",
      "Epoch 86/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.2053 - mae: 0.8427 - val_loss: 0.7554 - val_mae: 1.0708\n",
      "Epoch 87/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.2077 - mae: 0.8390 - val_loss: 0.7594 - val_mae: 1.0661\n",
      "Epoch 88/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1980 - mae: 0.8302 - val_loss: 0.7898 - val_mae: 1.0971\n",
      "Epoch 89/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1888 - mae: 0.8192 - val_loss: 0.7883 - val_mae: 1.0751\n",
      "Epoch 90/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1943 - mae: 0.8282 - val_loss: 0.7647 - val_mae: 1.0223\n",
      "Epoch 91/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1948 - mae: 0.8279 - val_loss: 0.7822 - val_mae: 1.0663\n",
      "Epoch 92/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.1839 - mae: 0.8163 - val_loss: 0.7642 - val_mae: 1.0648\n",
      "Epoch 93/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1833 - mae: 0.8154 - val_loss: 0.7698 - val_mae: 1.0675\n",
      "Epoch 94/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1816 - mae: 0.8124 - val_loss: 0.7815 - val_mae: 1.0957\n",
      "Epoch 95/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1814 - mae: 0.8111 - val_loss: 0.8045 - val_mae: 1.1084\n",
      "Epoch 96/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1747 - mae: 0.8009 - val_loss: 0.8002 - val_mae: 1.1188\n",
      "Epoch 97/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1711 - mae: 0.7979 - val_loss: 0.8113 - val_mae: 1.1069\n",
      "Epoch 98/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1673 - mae: 0.7947 - val_loss: 0.8164 - val_mae: 1.1111\n",
      "Epoch 99/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1664 - mae: 0.7912 - val_loss: 0.7984 - val_mae: 1.0763\n",
      "Epoch 100/100\n",
      "\u001b[1m395/395\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.1651 - mae: 0.7896 - val_loss: 0.8203 - val_mae: 1.1070\n",
      "✅ Entrenamiento del Modelo LSTM Finalizado.\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step\n",
      "\n",
      "--- 📈 EVALUACIÓN DEL MODELO LSTM ---\n",
      "El Coeficiente de Determinación (R^2) en el conjunto de prueba es: -0.0862\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "All arrays must be of the same length",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 199\u001b[39m\n\u001b[32m    194\u001b[39m \u001b[38;5;66;03m# --- 6. VISUALIZACIÓN DE LA COMPARACIÓN ---\u001b[39;00m\n\u001b[32m    195\u001b[39m \n\u001b[32m    196\u001b[39m \u001b[38;5;66;03m# Crear DataFrame para el R^2\u001b[39;00m\n\u001b[32m    197\u001b[39m df_test_filtered = df_test.iloc[TIME_STEPS:].copy().reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m199\u001b[39m df_results = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mCUADRANTE_ID\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_cuadrante_test_seq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFECHA\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test_filtered\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mFECHA\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mROBOS_REAL\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_test_seq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPREDICCION_ROBOS_REAL\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_real_lstm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Filtrar para Enero 2024\u001b[39;00m\n\u001b[32m    207\u001b[39m MES_A_EVALUAR = \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/frame.py:782\u001b[39m, in \u001b[36mDataFrame.__init__\u001b[39m\u001b[34m(self, data, index, columns, dtype, copy)\u001b[39m\n\u001b[32m    776\u001b[39m     mgr = \u001b[38;5;28mself\u001b[39m._init_mgr(\n\u001b[32m    777\u001b[39m         data, axes={\u001b[33m\"\u001b[39m\u001b[33mindex\u001b[39m\u001b[33m\"\u001b[39m: index, \u001b[33m\"\u001b[39m\u001b[33mcolumns\u001b[39m\u001b[33m\"\u001b[39m: columns}, dtype=dtype, copy=copy\n\u001b[32m    778\u001b[39m     )\n\u001b[32m    780\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    781\u001b[39m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m782\u001b[39m     mgr = \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    783\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma.MaskedArray):\n\u001b[32m    784\u001b[39m     \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mma\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/construction.py:503\u001b[39m, in \u001b[36mdict_to_mgr\u001b[39m\u001b[34m(data, index, columns, dtype, typ, copy)\u001b[39m\n\u001b[32m    499\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    500\u001b[39m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[32m    501\u001b[39m         arrays = [x.copy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/construction.py:114\u001b[39m, in \u001b[36marrays_to_mgr\u001b[39m\u001b[34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[32m    113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m         index = \u001b[43m_extract_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    116\u001b[39m         index = ensure_index(index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/pandas/core/internals/construction.py:677\u001b[39m, in \u001b[36m_extract_index\u001b[39m\u001b[34m(data)\u001b[39m\n\u001b[32m    675\u001b[39m lengths = \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mset\u001b[39m(raw_lengths))\n\u001b[32m    676\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(lengths) > \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mAll arrays must be of the same length\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m have_dicts:\n\u001b[32m    680\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    681\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mMixing dicts with non-Series may lead to ambiguous ordering.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    682\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: All arrays must be of the same length"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Concatenate, Flatten, LSTM, Dropout\n",
    "from tensorflow.keras.losses import Poisson\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # Ocultar advertencias\n",
    "\n",
    "# --- CONFIGURACIÓN Y CONSTANTES ---\n",
    "FILE_NAME = \"cuadrantes_negocios.csv\"\n",
    "NUM_CUADRANTES = 78\n",
    "EMBEDDING_DIM = 10 \n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 16\n",
    "TIME_STEPS = 3 # Ventana de tiempo (3 meses anteriores)\n",
    "\n",
    "# --- 1. CARGA, TRANSFORMACIÓN (ANCHO A LARGO) Y GENERACIÓN DE FEATURES ---\n",
    "\n",
    "def load_and_prepare_data(file_name):\n",
    "    \"\"\"Carga, transforma el formato ancho a largo y genera features de retardo.\"\"\"\n",
    "    try:\n",
    "        df_wide = pd.read_csv(file_name)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró el archivo '{file_name}'.\")\n",
    "        raise\n",
    "\n",
    "    df_wide.rename(columns={'CUADRANTE': 'CUADRANTE_ID', 'POBLACION': 'POBLACION_BASE'}, inplace=True)\n",
    "    \n",
    "    id_vars = ['CUADRANTE_ID', 'POBLACION_BASE']\n",
    "    value_vars = [col for col in df_wide.columns if col not in id_vars]\n",
    "\n",
    "    df_long = df_wide.melt(\n",
    "        id_vars=id_vars,\n",
    "        value_vars=value_vars,\n",
    "        var_name='MES_AÑO_STR',\n",
    "        value_name='ROBOS_TOTAL'\n",
    "    ).copy()\n",
    "\n",
    "    def parse_date(date_str):\n",
    "        parts = date_str.split(' ')\n",
    "        mes = parts[4] \n",
    "        año = parts[5] \n",
    "        return f'{año}-{mes}-01'\n",
    "\n",
    "    df_long['FECHA'] = df_long['MES_AÑO_STR'].apply(parse_date)\n",
    "    df_long['FECHA'] = pd.to_datetime(df_long['FECHA'])\n",
    "    df_long.sort_values(by=['CUADRANTE_ID', 'FECHA'], inplace=True)\n",
    "    df_long.drop(columns=['MES_AÑO_STR'], inplace=True)\n",
    "\n",
    "    df_long['AÑO'] = df_long['FECHA'].dt.year\n",
    "    df_long['MES'] = df_long['FECHA'].dt.month\n",
    "    df_long['ROBOS_t-1'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].shift(1)\n",
    "    df_long['ROBOS_t-12'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].shift(12)\n",
    "    df_long['MEDIA_MOVIL_3M'] = df_long.groupby('CUADRANTE_ID')['ROBOS_TOTAL'].rolling(window=3, min_periods=1).mean().reset_index(level=0, drop=True).shift(1)\n",
    "    \n",
    "    df_model_input = df_long.dropna(subset=['ROBOS_t-12']).copy()\n",
    "    \n",
    "    return df_model_input\n",
    "\n",
    "df_model_input = load_and_prepare_data(FILE_NAME)\n",
    "\n",
    "\n",
    "# --- 2. LIMPIEZA, NORMALIZACIÓN (SOLO FEATURES) Y CODIFICACIÓN ---\n",
    "\n",
    "numerical_and_target_cols = ['POBLACION_BASE', 'ROBOS_t-1', 'ROBOS_t-12', 'MEDIA_MOVIL_3M', 'ROBOS_TOTAL']\n",
    "for col in numerical_and_target_cols:\n",
    "    df_model_input[col] = pd.to_numeric(df_model_input[col], errors='coerce')\n",
    "\n",
    "df_model_input.dropna(subset=numerical_and_target_cols, inplace=True)\n",
    "df_model_input['CUADRANTE_ID'] = df_model_input['CUADRANTE_ID'].astype(np.int32)\n",
    "df_model_input['MES'] = df_model_input['MES'].astype(np.int32)\n",
    "\n",
    "# 2.2. Normalización Min-Max (SOLO FEATURES)\n",
    "scaler = MinMaxScaler()\n",
    "features_to_scale = ['POBLACION_BASE', 'ROBOS_t-1', 'ROBOS_t-12', 'MEDIA_MOVIL_3M']\n",
    "df_model_input[features_to_scale] = scaler.fit_transform(df_model_input[features_to_scale])\n",
    "\n",
    "# 2.3. Codificación One-Hot para el MES\n",
    "df_processed = pd.get_dummies(df_model_input, columns=['MES'], prefix='MES')\n",
    "\n",
    "\n",
    "# --- 3. DIVISIÓN DE DATOS Y PREPARACIÓN DE ARRAYS SEQUENCIALES ---\n",
    "\n",
    "FECHA_CORTE_VAL = pd.to_datetime('2023-01-01')\n",
    "FECHA_CORTE_TEST = pd.to_datetime('2024-01-01')\n",
    "\n",
    "df_train = df_processed[df_processed['FECHA'] < FECHA_CORTE_VAL]\n",
    "df_val = df_processed[(df_processed['FECHA'] >= FECHA_CORTE_VAL) & (df_processed['FECHA'] < FECHA_CORTE_TEST)]\n",
    "df_test = df_processed[df_processed['FECHA'] >= FECHA_CORTE_TEST]\n",
    "\n",
    "# Definición de Features para la LSTM\n",
    "features_lstm = [col for col in df_processed.columns if col not in ['CUADRANTE_ID', 'FECHA', 'ROBOS_TOTAL', 'AÑO']]\n",
    "\n",
    "\n",
    "def create_sequences(df, Y_values, time_steps):\n",
    "    \"\"\"Transforma datos tabulares en secuencias (Timesteps, Features) para LSTM.\"\"\"\n",
    "    Xs, Ys, Cuadrantes = [], [], []\n",
    "    \n",
    "    for id in df['CUADRANTE_ID'].unique():\n",
    "        df_cuadrante = df[df['CUADRANTE_ID'] == id].copy().reset_index(drop=True)\n",
    "        \n",
    "        # Iteramos a través de la serie del tiempo para crear la ventana\n",
    "        for i in range(len(df_cuadrante) - time_steps):\n",
    "            \n",
    "            # X_seq: Los 'time_steps' (3) meses anteriores para las features\n",
    "            X_seq = df_cuadrante.loc[i:(i + time_steps - 1), features_lstm].values\n",
    "            \n",
    "            # Y_val: El valor a predecir (ROBOS_TOTAL) justo después de la ventana\n",
    "            # Usamos el índice de df_cuadrante para obtener el valor real del target (Y)\n",
    "            Y_val = df_cuadrante.loc[i + time_steps, 'ROBOS_TOTAL']\n",
    "            \n",
    "            # Cuadrante ID para el Embedding\n",
    "            Cuadrante_ID_val = df_cuadrante.loc[i + time_steps, 'CUADRANTE_ID']\n",
    "            \n",
    "            Xs.append(X_seq)\n",
    "            Ys.append(Y_val)\n",
    "            Cuadrantes.append(Cuadrante_ID_val)\n",
    "\n",
    "    # Conversión a arrays de NumPy con el tipo correcto\n",
    "    return np.array(Xs, dtype=np.float32), np.array(Ys, dtype=np.float32), np.array(Cuadrantes, dtype=np.int32)\n",
    "\n",
    "\n",
    "# Generar las nuevas entradas secuenciales\n",
    "X_train_seq, Y_train_seq, X_cuadrante_train_seq = create_sequences(df_train, df_train['ROBOS_TOTAL'], TIME_STEPS)\n",
    "X_val_seq, Y_val_seq, X_cuadrante_val_seq = create_sequences(df_val, df_val['ROBOS_TOTAL'], TIME_STEPS)\n",
    "X_test_seq, Y_test_seq, X_cuadrante_test_seq = create_sequences(df_test, df_test['ROBOS_TOTAL'], TIME_STEPS)\n",
    "\n",
    "# --- MODIFICACIÓN EN EL PASO 4 (build_lstm_model) ---\n",
    "# [Solo mostraré la función build_lstm_model modificada]\n",
    "\n",
    "def build_lstm_model(num_cuadrantes, embedding_dim, seq_length, num_features):\n",
    "    \n",
    "    # 1. Rama Embedding (CUADRANTE_ID)\n",
    "    input_cuadrante = Input(shape=(1,), name='input_cuadrante')\n",
    "    embedding_layer = Embedding(\n",
    "        input_dim=num_cuadrantes + 1, \n",
    "        output_dim=embedding_dim,\n",
    "        input_length=1,\n",
    "        name='embedding_cuadrante'\n",
    "    )(input_cuadrante)\n",
    "    flatten_embedding = Flatten()(embedding_layer)\n",
    "\n",
    "    # 2. Rama Secuencial (LSTM)\n",
    "    input_sequence = Input(shape=(seq_length, num_features), name='input_sequence')\n",
    "    \n",
    "    # Capa LSTM 1: Aumentamos unidades y añadimos return_sequences=True\n",
    "    lstm_out = LSTM(128, activation='tanh', return_sequences=True)(input_sequence) \n",
    "    lstm_out = Dropout(0.3)(lstm_out) # Aumentamos Dropout\n",
    "\n",
    "    # Capa LSTM 2: Añadimos una segunda capa LSTM para profundidad\n",
    "    lstm_out = LSTM(64, activation='tanh', return_sequences=False)(lstm_out)\n",
    "    lstm_out = Dropout(0.3)(lstm_out)\n",
    "\n",
    "    # 3. Concatenación y Capas Profundas\n",
    "    combined = Concatenate()([flatten_embedding, lstm_out])\n",
    "    \n",
    "    # Capas Densa Finales (Aumentamos unidades)\n",
    "    dense_1 = Dense(128, activation='relu')(combined)\n",
    "    dense_2 = Dense(64, activation='relu')(dense_1)\n",
    "    \n",
    "    # 4. Capa de Salida: Softplus y Poisson Loss\n",
    "    output_layer = Dense(1, activation='softplus', name='prediccion_final')(dense_2)\n",
    "\n",
    "    model = Model(inputs=[input_cuadrante, input_sequence], outputs=output_layer)\n",
    "    model.compile(optimizer='adam', loss=Poisson(), metrics=['mae'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# --- 5. EVALUACIÓN Y CÁLCULO FINAL DEL R^2 ---\n",
    "\n",
    "# 5.1. Predicción en escala de conteo (no normalizada)\n",
    "y_pred_real_lstm = model.predict([X_cuadrante_test_seq, X_test_seq])\n",
    "\n",
    "# 5.2. Calcular el R^2\n",
    "r2_lstm = r2_score(Y_test_seq, y_pred_real_lstm.flatten())\n",
    "\n",
    "print(\"\\n--- 📈 EVALUACIÓN DEL MODELO LSTM ---\")\n",
    "print(f\"El Coeficiente de Determinación (R^2) en el conjunto de prueba es: {r2_lstm:.4f}\")\n",
    "\n",
    "# --- 6. VISUALIZACIÓN DE LA COMPARACIÓN ---\n",
    "\n",
    "# Crear DataFrame para el R^2\n",
    "df_test_filtered = df_test.iloc[TIME_STEPS:].copy().reset_index(drop=True)\n",
    "\n",
    "df_results = pd.DataFrame({\n",
    "    'CUADRANTE_ID': X_cuadrante_test_seq,\n",
    "    'FECHA': df_test_filtered['FECHA'].values,\n",
    "    'ROBOS_REAL': Y_test_seq,\n",
    "    'PREDICCION_ROBOS_REAL': y_pred_real_lstm.flatten()\n",
    "})\n",
    "\n",
    "# Filtrar para Enero 2024\n",
    "MES_A_EVALUAR = 1\n",
    "df_enero_2024 = df_results[\n",
    "    (df_results['FECHA'].dt.month == MES_A_EVALUAR) & \n",
    "    (df_results['FECHA'].dt.year == 2024)\n",
    "].copy()\n",
    "\n",
    "df_enero_2024['PREDICCION_ROBOS_REAL'] = df_enero_2024['PREDICCION_ROBOS_REAL'].round(0).astype(int)\n",
    "df_enero_2024['ROBOS_REAL'] = df_enero_2024['ROBOS_REAL'].round(0).astype(int)\n",
    "df_enero_2024['ERROR (Real - Pred)'] = df_enero_2024['ROBOS_REAL'] - df_enero_2024['PREDICCION_ROBOS_REAL']\n",
    "df_enero_2024 = df_enero_2024.sort_values(by='PREDICCION_ROBOS_REAL', ascending=False)\n",
    "\n",
    "df_final = df_enero_2024[['CUADRANTE_ID', 'ROBOS_REAL', 'PREDICCION_ROBOS_REAL', 'ERROR (Real - Pred)']]\n",
    "\n",
    "print(f\"\\n--- Comparación Enero 2024 (Ordenado por Predicción) ---\")\n",
    "print(df_final.head(20).to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39192ac1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
